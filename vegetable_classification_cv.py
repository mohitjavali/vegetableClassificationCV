# -*- coding: utf-8 -*-
"""ninjacart_classification_cv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tQLa00Ot4mNHtOjKQ7gMc1Fan_vXNDkE

## Importing necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
from numpy.linalg import norm
import pickle
from tqdm import tqdm, tqdm_notebook
import os
import random
import time
import math
import tensorflow as tf
from tensorflow import keras
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import sklearn.metrics as metrics
from sklearn.metrics import classification_report
import PIL
from PIL import Image
from sklearn.neighbors import NearestNeighbors
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from tensorflow.keras.layers import Input, DepthwiseConv2D
from tensorflow.keras.layers import Conv2D, BatchNormalization
from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense
from tensorflow.python.keras import regularizers
from tensorflow.keras import Model
import glob
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

"""## Loading the dataset"""

# https://drive.google.com/file/d/1WCor5ucciwvSjI2J_-CVYsNmXKh_g_5Z/view?usp=sharing
!gdown 1WCor5ucciwvSjI2J_-CVYsNmXKh_g_5Z

!unzip ninjacart_data.zip

"""## Visualize the dataset

#### i> For Train Data
"""

class_dirs = os.listdir("ninjacart_data/train/") # list all directories inside "train" folder
image_dict = {} # dict to store image array(key) for every class(value)
count_dict = {} # dict to store count of files(key) for every class(value)
# iterate over all class_dirs
for cls in class_dirs:
    # get list of all paths inside the subdirectory
    file_paths = glob.glob(f'ninjacart_data/train/{cls}/*')
    # count number of files in each class and add it to count_dict
    count_dict[cls] = len(file_paths)
    # select random item from list of image paths
    image_path = random.choice(file_paths)
    # load image using keras utility function and save it in image_dict
    image_dict[cls] = tf.keras.utils.load_img(image_path)

## Viz Random Sample from each class

plt.figure(figsize=(15, 12))
# iterate over dictionary items (class label, image array)
for i, (cls,img) in enumerate(image_dict.items()):    
    # create a subplot axis
    ax = plt.subplot(3, 4, i + 1)
    # plot each image
    plt.imshow(img)
    # set "class name" along with "image size" as title 
    plt.title(f'{cls}, {img.size}')
    plt.axis("off")

## Let's now Plot the Data Distribution of Training Data across Classes
df_count_train = pd.DataFrame({
    "class": count_dict.keys(),     # keys of count_dict are class labels
    "count": count_dict.values(),   # value of count_dict contain counts of each class
})
print("Count of training samples per class:\n", df_count_train)

# draw a bar plot using pandas in-built plotting function
df_count_train.plot.bar(x='class', y='count', title="Training Data Count per class")

"""#### ii> For Test Data"""

class_dirs = os.listdir("ninjacart_data/test/") # list all directories inside "train" folder
image_dict = {} # dict to store image array(key) for every class(value)
count_dict = {} # dict to store count of files(key) for every class(value)
# iterate over all class_dirs
for cls in class_dirs:
    # get list of all paths inside the subdirectory
    file_paths = glob.glob(f'ninjacart_data/test/{cls}/*')
    # count number of files in each class and add it to count_dict
    count_dict[cls] = len(file_paths)
    # select random item from list of image paths
    image_path = random.choice(file_paths)
    # load image using keras utility function and save it in image_dict
    image_dict[cls] = tf.keras.utils.load_img(image_path)

## Viz Random Sample from each class

plt.figure(figsize=(15, 12))
# iterate over dictionary items (class label, image array)
for i, (cls,img) in enumerate(image_dict.items()):    
    # create a subplot axis
    ax = plt.subplot(3, 4, i + 1)
    # plot each image
    plt.imshow(img)
    # set "class name" along with "image size" as title 
    plt.title(f'{cls}, {img.size}')
    plt.axis("off")

## Let's now Plot the Data Distribution of Training Data across Classes
df_count_train = pd.DataFrame({
    "class": count_dict.keys(),     # keys of count_dict are class labels
    "count": count_dict.values(),   # value of count_dict contain counts of each class
})
print("Count of training samples per class:\n", df_count_train)

# draw a bar plot using pandas in-built plotting function
df_count_train.plot.bar(x='class', y='count', title="Training Data Count per class")

"""## Data Preprocessing: Resizing, Standardization"""

def preprocess(train_data, val_data, test_data, target_height=227, target_width=227):

    # Data Processing Stage with resizing and rescaling operations
    data_preprocess = tf.keras.Sequential(
        name="data_preprocess",
        layers=[
            tf.keras.layers.Resizing(target_height, target_width),
            tf.keras.layers.Rescaling(1.0/255),
        ]
    )

    # Perform Data Processing on the train, test dataset
    train_ds = train_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

!pip install split-folders

import splitfolders

input_folder = "ninjacart_data/train/"
splitfolders.ratio(input_folder, output="output", seed=1337, ratio=(.8, .2), group_prefix=None, move=False)

train_data = tf.keras.utils.image_dataset_from_directory("output/train/",shuffle=True, seed=123,image_size=(227, 227),batch_size=32)
val_data = tf.keras.utils.image_dataset_from_directory("output/val/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)
test_data = tf.keras.utils.image_dataset_from_directory("ninjacart_data/test/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)

train_ds, val_ds, test_ds = preprocess(train_data, val_data, test_data)

"""## List of classes in the dataset"""

categories = train_data.class_names
print(categories)

"""## Dealing with Class Imbalance if there is any!
### With Class weights
"""

DIR = 'ninjacart_data/train/indian market/'
COUNT_INDIAN_MARKET = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])
print(f'Indian Market images count in training set: {COUNT_INDIAN_MARKET}')

DIR = 'ninjacart_data/train/onion/'
COUNT_ONION = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])
print(f'Onion images count in training set: {COUNT_ONION}')

DIR = 'ninjacart_data/train/potato/'
COUNT_POTATO = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])
print(f'Potato images count in training set: {COUNT_POTATO}')

DIR = 'ninjacart_data/train/tomato/'
COUNT_TOMATO = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])
print(f'Tomato images count in training set: {COUNT_TOMATO}')

TOTAL_COUNT = COUNT_INDIAN_MARKET+COUNT_ONION+COUNT_POTATO+COUNT_TOMATO
print('Total Count of images:', TOTAL_COUNT)

# Scaling by total/2 helps keep the loss to a similar magnitude.
# The sum of the weights of all examples stays the same.

weight_for_0 = (1 / COUNT_INDIAN_MARKET) * (TOTAL_COUNT)  / 2.0
weight_for_1 = (1 / COUNT_ONION) * (TOTAL_COUNT) / 2.0
weight_for_2 = (1 / COUNT_POTATO) * (TOTAL_COUNT) / 2.0
weight_for_3 = (1 / COUNT_TOMATO) * (TOTAL_COUNT) / 2.0

class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3}

print("Weight for class 0: {:.2f}".format(weight_for_0))
print("Weight for class 1: {:.2f}".format(weight_for_1))
print("Weight for class 2: {:.2f}".format(weight_for_2))
print("Weight for class 3: {:.2f}".format(weight_for_3))

"""## Baseline Model

#### Model Building & Training
"""

def baseline(height=227, width=227):
    num_classes = 4
    hidden_size = 256

    model = tf.keras.Sequential(
        name="baseline_cnn_model",
        layers=[
            tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding="same", activation='relu', input_shape=(height, width, 3)),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(units=hidden_size, activation='relu'),
            tf.keras.layers.Dense(units=num_classes, activation='softmax')
        ]
    )
    return model

model = baseline()
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=15)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the Baseline Model:<br>
1> I feel the model has learnt because the val accuracy is 82% but as the train accuracy is almost 100%, there are chances that the model might have overfit because the test accuracy is just 70%.<br>
2> You can observe that the number of parameters are very large. And maximum of it comes from last but one layer.

"""



"""## Modification 1 with Baseline Model

We will do the following modifications & check again:<br>
1> Add Batch Normalization after every Conv2D and Dense layers.<br>
2> Add Dropout after Dense layers

#### Model Building & Training
"""

def mod1_cnn_model(height=128, width=128):
    num_classes = 4
    hidden_size = 256

    model = keras.Sequential(
        name="mod1_cnn_model",
        layers=[
            tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding="same", input_shape=(height, width, 3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same"),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same"),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding="same"),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding="same"),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            # layers.MaxPooling2D(),
            # layers.Flatten(),
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(units=hidden_size),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(units=num_classes, activation='softmax')
        ]
    )
    return model

model = mod1_cnn_model(height=227, width=227)
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=30)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the Modification 1 Model:<br>
1> I feel the model has learnt well because even the accuracy for test data is around 92%. Since train data has a very high accuracy, there are chances of getting Overfitted. Let's try to deal this in the next modification.<br>
2> Number of parameters have also drastically reduced.


"""



"""## Modification 2 with Baseline Model

We will do the following modifications to above model & check again:<br>
1> We will add L2 regularization to Conv2D and Dense layers

#### Model Building & Training
"""

def mod2_cnn_model(height=128, width=128):
    num_classes = 4
    hidden_size = 256

    model = keras.Sequential(
        name="model_cnn_2",
        layers=[
            tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding="same", input_shape=(height, width, 3),
                            kernel_regularizer=regularizers.l2(1e-3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same",
                            kernel_regularizer=regularizers.l2(1e-3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same",
                            kernel_regularizer=regularizers.l2(1e-3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding="same",
                            kernel_regularizer=regularizers.l2(1e-3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding="same",
                            kernel_regularizer=regularizers.l2(1e-3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            # layers.MaxPooling2D(),
            # layers.Flatten(),
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(units=hidden_size, kernel_regularizer=regularizers.l2(1e-3)),
            tf.keras.layers.Activation("relu"),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(units=num_classes, activation='softmax')
        ]
    )
    return model

model = mod2_cnn_model(height=227, width=227)
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=30)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the Baseline Model:<br>
1> Slightly we can see that the Overfitting is reduced.

## Modification 3 with Baseline Model

We will do the following modifications & check again:<br>
1> Applying different Data Augmentation strategies.

#### Data Augmentation & Data Preprocessing
"""

def preprocess_v2(train_data, val_data, test_data, target_height=256, target_width=256):

    # Data Processing Stage with resizing and rescaling operations #same as before for test,val
    data_preprocess = keras.Sequential(
        name="data_preprocess",
        layers=[
            tf.keras.layers.Resizing(target_height, target_width),
            tf.keras.layers.Rescaling(1.0/255),
        ]
    )

    # Data Processing Stage with resizing and rescaling operations
    data_augmentation = keras.Sequential(
        name="data_augmentation",
        layers=[
            tf.keras.layers.Resizing(156, 156), # First resize to 156,156
            tf.keras.layers.RandomCrop(target_height, target_width), # Then randomly crop 128,128 region
            tf.keras.layers.RandomBrightness(0.2), # Modify brightness by 0.2 factor
            tf.keras.layers.Rescaling(1.0/255), # Finally rescale
        ]
    )

    # Perform Data Processing on the train, val, test dataset
    train_ds = train_data.map(
        lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE
    ).prefetch(tf.data.AUTOTUNE)
    val_ds = val_data.map(
        lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE
    ).prefetch(tf.data.AUTOTUNE)
    test_ds = test_data.map(
        lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE
    ).prefetch(tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = preprocess_v2(train_data, val_data, test_data)

"""#### Model Building & Training"""

model = mod2_cnn_model(height=256, width=256)
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=100)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the Modification 3 Model:<br>
1> The Overfitting problem seems to have been dealt compared to other models above.


"""



"""## VGG16 without Pretrained

#### Model Building & Training
"""

def vgg16_without_pretrained(height=224, width=224):
    num_classes = 4
    hidden_size = 256

    model = keras.Sequential(
        name="vgg16_without_pretrained",
        layers=[
            tf.keras.layers.Input(shape = (224 ,224, 3)),
            tf.keras.layers.Conv2D(64, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(64, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides= (2,2)),

            tf.keras.layers.Conv2D(128, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(128, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides= (2,2)),

            tf.keras.layers.Conv2D(256, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(256, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(256, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(256, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides= (2,2)),

            tf.keras.layers.Conv2D(512, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(512, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(512, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(512, kernel_size=(3,3),padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides= (2,2)),

            tf.keras.layers.Conv2D(512, kernel_size=(3,3),padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(512, kernel_size=(3,3),padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(512, kernel_size=(3,3),padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.Conv2D(512, kernel_size=(3,3), padding= 'same',
                            activation= 'relu'),
            tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides= (2,2)),

            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(4096, activation= 'relu'),
            tf.keras.layers.Dropout(0.5),
            #tf.keras.layers.Dense(4096, activation= 'relu'),
            #tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(4, activation= 'softmax')
        ]
    )
    return model

model = vgg16_without_pretrained()
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir



"""#### Data Preprocessing: Resizing, Standardization"""

def preprocess(train_data, val_data, test_data, target_height=224, target_width=224):

    # Data Processing Stage with resizing and rescaling operations
    data_preprocess = tf.keras.Sequential(
        name="data_preprocess",
        layers=[
            tf.keras.layers.Resizing(target_height, target_width),
            tf.keras.layers.Rescaling(1.0/255),
        ]
    )

    # Perform Data Processing on the train, test dataset
    train_ds = train_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

#!pip install split-folders

#import splitfolders

#input_folder = "ninjacart_data/train/"
#splitfolders.ratio(input_folder, output="output", seed=1337, ratio=(.8, .2), group_prefix=None, move=False)

train_data = tf.keras.utils.image_dataset_from_directory("output/train/",shuffle=True, seed=123,image_size=(227, 227),batch_size=32)
val_data = tf.keras.utils.image_dataset_from_directory("output/val/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)
test_data = tf.keras.utils.image_dataset_from_directory("ninjacart_data/test/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)

train_ds, val_ds, test_ds = preprocess(train_data, val_data, test_data)

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=5)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the Baseline Model:<br>
1> This model has poorly learnt. It has just learnt all the images as potatoes.<br>
2> Since it is getting trained from the begining, this might have not learnt thoroughly.

"""



"""## VGG16 with Pretrained

#### Model Building & Training
"""

def vgg16_with_pretrained(height=128, width=128):
    num_classes = 4
    hidden_size = 256

    pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=[height,width, 3])
    pretrained_model.trainable=False
    vgg16_model = tf.keras.Sequential([
        pretrained_model,
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(256, activation= 'relu'),
        tf.keras.layers.Dropout(0.25),
        tf.keras.layers.Dense(64, activation= 'relu'),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])
    return vgg16_model

model = vgg16_with_pretrained()
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

"""#### Data Preprocessing: Resizing, Standardization"""

def preprocess(train_data, val_data, test_data, target_height=128, target_width=128):

    # Data Processing Stage with resizing and rescaling operations
    data_preprocess = tf.keras.Sequential(
        name="data_preprocess",
        layers=[
            tf.keras.layers.Resizing(target_height, target_width),
            tf.keras.layers.Rescaling(1.0/255),
        ]
    )

    # Perform Data Processing on the train, test dataset
    train_ds = train_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

#!pip install split-folders

#import splitfolders

#input_folder = "ninjacart_data/train/"
#splitfolders.ratio(input_folder, output="output", seed=1337, ratio=(.8, .2), group_prefix=None, move=False)

train_data = tf.keras.utils.image_dataset_from_directory("output/train/",shuffle=True, seed=123,image_size=(227, 227),batch_size=32)
val_data = tf.keras.utils.image_dataset_from_directory("output/val/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)
test_data = tf.keras.utils.image_dataset_from_directory("ninjacart_data/test/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)

train_ds, val_ds, test_ds = preprocess(train_data, val_data, test_data)

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=15)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the above Model:<br>
1> As previous model, it was underfitting and has not learnt anything because I had done 3 main mistakes:

    (i) I used 224\*224 image size in the input which was ver big, instead using 128\*128 increased the accuracy. <br>
    (ii) I used Flatten() instead GlobalAveragePoling().<br>
    (iii) Increased the Fully Connected Layers.

"""



"""## Resnet50

#### Model Building & Training
"""

def resnet50_pretrained(height=128, width=128):
    num_classes = 4
    hidden_size = 256

    pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[height,width,3])
    pretrained_model.trainable=False
    resnet_model = tf.keras.Sequential([pretrained_model,
                                        tf.keras.layers.Flatten(),
                                        tf.keras.layers.Dense(128, activation= 'relu'),
                                        tf.keras.layers.Dropout(0.25),
                                        tf.keras.layers.Dense(32, activation= 'relu'),
                                        tf.keras.layers.Dense(num_classes, activation='softmax')])
    return resnet_model

model = resnet50_pretrained()
model.summary()

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

"""#### Data Preprocessing: Resizing, Standardization"""

def preprocess(train_data, val_data, test_data, target_height=128, target_width=128):

    # Data Processing Stage with resizing and rescaling operations
    data_preprocess = tf.keras.Sequential(
        name="data_preprocess",
        layers=[
            tf.keras.layers.Resizing(target_height, target_width),
            tf.keras.layers.Rescaling(1.0/255),
        ]
    )

    # Perform Data Processing on the train, test dataset
    train_ds = train_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

#!pip install split-folders

#import splitfolders

#input_folder = "ninjacart_data/train/"
#splitfolders.ratio(input_folder, output="output", seed=1337, ratio=(.8, .2), group_prefix=None, move=False)

train_data = tf.keras.utils.image_dataset_from_directory("output/train/",shuffle=True, seed=123,image_size=(227, 227),batch_size=32)
val_data = tf.keras.utils.image_dataset_from_directory("output/val/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)
test_data = tf.keras.utils.image_dataset_from_directory("ninjacart_data/test/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)

train_ds, val_ds, test_ds = preprocess(train_data, val_data, test_data)

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=25)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the above Model:<br>
1> Tried many things to improve the model - epochs, flatten/GAP, FCs; Resnet did not learn more. We just got Test Accuracy = 60%.

"""



"""## Mobilenet

#### Model Building & Training
"""

def mobilenet_pretrained(height=128, width=128):
    num_classes = 4
    hidden_size = 256

    pretrained_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=[height,width,3])
    pretrained_model.trainable=False
    mobilenet_model = tf.keras.Sequential([pretrained_model,
                                        tf.keras.layers.GlobalAveragePooling2D(),
                                        tf.keras.layers.Dense(128, activation= 'relu'),
                                        tf.keras.layers.Dense(64, activation= 'relu'),
                                        tf.keras.layers.Dense(num_classes, activation='softmax')])
    return mobilenet_model

model = mobilenet_pretrained()
model.summary()

#plot the model
tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_dtype=False,show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)

#!pip install tensorboard

# tensorboard setup for visualization
log_dir = "pistol_Log" 
!rm -rf log_dir

"""#### Data Preprocessing: Resizing, Standardization"""

def preprocess(train_data, val_data, test_data, target_height=128, target_width=128):

    # Data Processing Stage with resizing and rescaling operations
    data_preprocess = tf.keras.Sequential(
        name="data_preprocess",
        layers=[
            tf.keras.layers.Resizing(target_height, target_width),
            tf.keras.layers.Rescaling(1.0/255),
        ]
    )

    # Perform Data Processing on the train, test dataset
    train_ds = train_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)

    return train_ds, val_ds, test_ds

#!pip install split-folders

#import splitfolders

#input_folder = "ninjacart_data/train/"
#splitfolders.ratio(input_folder, output="output", seed=1337, ratio=(.8, .2), group_prefix=None, move=False)

train_data = tf.keras.utils.image_dataset_from_directory("output/train/",shuffle=True, seed=123,image_size=(227, 227),batch_size=32)
val_data = tf.keras.utils.image_dataset_from_directory("output/val/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)
test_data = tf.keras.utils.image_dataset_from_directory("ninjacart_data/test/",shuffle=False, seed=123,image_size=(227, 227),batch_size=32)

train_ds, val_ds, test_ds = preprocess(train_data, val_data, test_data)

def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path="/tmp/checkpoint"):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"])
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight = class_weight, callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_callback])
    return model_fit

model_fit = compile_train_v1(model, train_ds, val_ds, epochs=5)

# Commented out IPython magic to ensure Python compatibility.
# Implement a TensorBoard callback to log each of our model metrics for each model during the training process. 
# %load_ext tensorboard
# %tensorboard --logdir={log_dir}

"""#### Plotting Accuracy, Loss v/s Epochs for Train and Validation Data"""

fig, ax = plt.subplots(1, 2, figsize=(20, 7))
ax = ax.ravel()

for i, met in enumerate(["accuracy", "loss"]):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history["val_" + met])
    ax[i].set_title("Model {}".format(met))
    ax[i].set_xlabel("epochs")
    ax[i].set_ylabel(met)
    ax[i].legend(["train", "val"])

"""#### Confusion Matrix, Precision & Recall"""

def ConfusionMatrix(model, ds, label_list):
# Note: This logic doesn't work with shuffled datasets
    # run model prediction and obtain probabilities
    y_pred = model.predict(ds)
    # get list of predicted classes by taking argmax of the probabilities(y_pred)
    predicted_categories = tf.argmax(y_pred, axis=1)
    # create list of all "y"s labels, by iterating over test dataset
    true_categories = tf.concat([y for x, y in ds], axis=0)

    print(classification_report(true_categories, predicted_categories))

    # generate confusion matrix and plot it
    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch 
    sns.heatmap(cm, annot=True, xticklabels=label_list, yticklabels=label_list, cmap="YlGnBu", fmt='g')
    plt.show()

ConfusionMatrix(model, test_ds, test_data.class_names)

"""#### Evaluate Accuracy & Loss of the above model for Test Data """

# Evaluate the model
loss, acc = model.evaluate(test_ds, verbose=2)
print("Accuracy of the Model with Test Data: {:5.2f}%".format(100 * acc))
print("Loss of the Model with Test Data: {:5.4f}".format(loss))

"""#### Visualizing Final Predictions of the above Model for few random data in test dataset"""

def plot_image(pred_array, true_label, img):
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(pred_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ".format(class_names[predicted_label],
                                100*np.max(pred_array),
                                ),
                                color=color)

true_categories = tf.concat([y for x, y in test_ds], axis=0)
images = tf.concat([x for x, y in test_ds], axis=0)
y_pred = model.predict(test_ds)
class_names = test_data.class_names

# Randomly sample 15 test images and plot it with their predicted labels, and the true labels.
indices = random.sample(range(len(images)), 15)
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(4*num_cols, 2*num_rows))
for i,index in enumerate(indices):
  plt.subplot(num_rows, num_cols, i+1)
  plot_image(y_pred[index], true_categories[index], images[index])

plt.tight_layout()
plt.show()

"""Inference of the above Model:<br>
1> This model has really learnt better than any other above models with Test Accuracy = 92%.

"""

